---
last_modified_on: "2020-03-28"
$schema: "/.meta/.schemas/guides.json"
title: "Send logs from Kafka to an HTTP endpoint"
description: "A guide to quickly, and correctly, send logs from Kafka to an HTTP endpoint."
author_github: https://github.com/binarylogic
cover_label: "Kafka to HTTP Integration"
tags: ["type: tutorial","domain: sources","domain: sinks","source: kafka","sink: http"]
---

import ConfigExample from '@site/src/components/ConfigExample';
import InstallationCommand from '@site/src/components/InstallationCommand';
import SVG from 'react-inlinesvg';

So you want to send logs from Kafka to an HTTP endpoint? Sounds simple! Sadly, it is not.
When you account for x, y, and z, you quickly realize this is no easy endaevor.
Especially for high volume product environments! Fear not! This guide will get
you up and running in minutes.

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     website/guides/integrate/sources/kafka/http.md.erb
-->

## What We'll Accomplish

<ol className="list--checks list--lg list--semi-bold list--primary list--flush">
  <li>
    Consume one or more Kafka topics.
    <ol>
      <li>Automatically discover new files with glob patterns.</li>
      <li>Checkpoint your position to ensure data is not lost between restarts.</li>
      <li>Enrich your logs with useful Kafka context.</li>
    </ol>
  </li>
  <li>
    Send logs over the HTTP protocol.
    <ol>
      <li>Batch and compress data to maximize throughput.</li>
      <li>Optionally set custom headers.</li>
      <li>Automatically retry failed requests, with backoff.</li>
      <li>Buffer your data in-memory or on-disk for performance and durability.</li>
    </ol>
  </li>
  <li className="list--li--arrow list--li--pink">All in just a few minutes. Let's get started!</li>
</ol>

## How It Works

The [service deployment strategy][docs.strategies.service] treats Vector like a
separate service. It is desigend to receive data from an upstream source and
fan-out to one or more destinations. Typically, upstream sources are other
Vector instances sending data via the [`vector` sink][docs.sinks.vector], but
can be collected through any of Vector's [sources][docs.sources]. The following
diagram demonstrates how it works.

<SVG src="/img/deployment-strategies-docker-service.svg" />

## Tutorial

<div className="steps steps--h3">
<ol>
<li>

### Install Vector

<InstallationCommand />

</li>
<li>

### Configure Vector

<ConfigExample
  format="toml"
  path="vector.toml"
  sourceName={"kafka"}
  sinkName={"http"} />

</li>
<li>

### Start Vector

```bash
vector --config vector.toml
```

That's it! Simple and to the point. Hit `ctrl+c` to exit.

</li>
</ol>
</div>


[docs.sinks.vector]: /docs/reference/sinks/vector/
[docs.sources]: /docs/reference/sources/
[docs.strategies.service]: /docs/setup/deployment/strategies/service/
