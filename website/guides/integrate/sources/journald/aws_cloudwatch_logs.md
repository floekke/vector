---
last_modified_on: "2020-03-28"
$schema: "/.meta/.schemas/guides.json"
title: "Send logs from Journald to AWS Cloudwatch"
description: "A guide to quickly, and correctly, send logs from Journald to AWS Cloudwatch."
author_github: https://github.com/binarylogic
cover_label: "Journald to AWS Cloudwatch Logs Integration"
tags: ["type: tutorial","domain: sources","domain: sinks","source: journald","sink: aws_cloudwatch_logs"]
---

import ConfigExample from '@site/src/components/ConfigExample';
import InstallationCommand from '@site/src/components/InstallationCommand';
import SVG from 'react-inlinesvg';

So you want to send logs from Journald to AWS Cloudwatch? Sounds simple! Sadly, it is not.
When you account for x, y, and z, you quickly realize this is no easy endaevor.
Especially for high volume product environments! Fear not! This guide will get
you up and running in minutes.

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     website/guides/integrate/sources/journald/aws_cloudwatch_logs.md.erb
-->

## What We'll Accomplish

<ol className="list--checks list--lg list--semi-bold list--primary list--flush">
  <li>
    Collect Journald/Systemd logs.
    <ol>
      <li>Filter which Systemd units you collect them from.</li>
      <li>Checkpoint your position to ensure data is not lost between restarts.</li>
      <li>Enrich your logs with useful Systemd context.</li>
    </ol>
  </li>
  <li>
    Send logs to AWS Cloudwatch.
    <ol>
      <li>Dynamically partition logs across CloudWatch groups and streams.</li>
      <li>Batch data to maximize throughput.</li>
      <li>Automatically retry failed requests, with backoff.</li>
      <li>Buffer your data in-memory or on-disk for performance and durability.</li>
    </ol>
  </li>
  <li className="list--li--arrow list--li--pink">All in just a few minutes. Let's get started!</li>
</ol>

## How It Works

The [daemon deployment strategy][docs.strategies.daemon] is designed for data
collection on a single host. Vector runs in the background, in its own process,
collecting _all_ data for that host. Typically data is collected from a process
manager, such as Journald via Vector's [`journald`
source][docs.sources.journald], but can be collected through any of Vector's
[sources][docs.sources]. The following diagram demonstrates how it works.

<SVG src="/img/deployment-strategies-docker-daemon.svg" />

## Tutorial

<div className="steps steps--h3">
<ol>
<li>

### Install Vector

<InstallationCommand />

</li>
<li>

### Configure Vector

<ConfigExample
  format="toml"
  path="vector.toml"
  sourceName={"journald"}
  sinkName={"aws_cloudwatch_logs"} />

</li>
<li>

### Start Vector

```bash
vector --config vector.toml
```

That's it! Simple and to the point. Hit `ctrl+c` to exit.

</li>
</ol>
</div>


[docs.sources.journald]: /docs/reference/sources/journald/
[docs.sources]: /docs/reference/sources/
[docs.strategies.daemon]: /docs/setup/deployment/strategies/daemon/
