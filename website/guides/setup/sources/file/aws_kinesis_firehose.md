---
last_modified_on: "2020-03-24"
title: "Send File logs to AWS Kinesis Firehose"
description: "A guide to quickly, and correctly, send File logs to AWS Kinesis Firehose."
domain: configuring
platform_name: null
sink_name: "aws_kinesis_firehose"
source_name: "file"
tags: ["source: file","sink: aws_kinesis_firehose"]
---

import ConfigExample from '@site/src/components/ConfigExample';
import InstallationCommand from '@site/src/components/InstallationCommand';
import SVG from 'react-inlinesvg';

> "I just wanna, like, send my File logs to AWS Kinesis Firehose -- why is all of this so complicated?"
>
> â€” developers

So you want to send File logs to AWS Kinesis Firehose? Sounds simple! Sadly, it is not.
When you account for x, y, and z, you quickly realize this is no easy endaevor.
Especially for high volume product environments! Fear not! This guide will get
you up and running in minutes.

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     website/guides/setup/sources/file/aws_kinesis_firehose.md.erb
-->

## What We'll Accomplish In This Guide

<ol className="list--checks list--lg list--semi-bold list--primary list--flush">
  <li>
    Tail one or more files.
    <ol>
      <li>Automatically discover new files with glob patterns.</li>
      <li>Merge multi-line logs into one event.</li>
      <li>Checkpoint your position to ensure data is not lost between restarts.</li>
      <li>Enrich your logs with useful file and host-level context.</li>
    </ol>
  </li>
  <li>
    Send logs to AWS Kinesis Firehose.
    <ol>
      <li>Batch data to maximize throughput.</li>
      <li>Automatically retry failed requests, with backoff.</li>
      <li>Buffer your data in-memory or on-disk for performance and durability.</li>
    </ol>
  </li>
  <li className="list--li--arrow list--li--pink">All in just a few minutes. Let's get started!</li>
</ol>

## How We'll Do It

<SVG src="/img/deployment-strategies-docker-daemon.svg" />

As shown in the diagram above, the daemon deployment strategy is designed for
data collection on a single host. Vector is deplyed in it's own container,
collecting and forwarding all data on the host.

## A Simple Step-By-Step Tutorial

<div className="steps steps--h3">

<ol>
<li>

### Install Vector

<InstallationCommand />

</li>
<li>

### Configure Vector

<ConfigExample
  format="toml"
  path="vector.toml"
  sourceName={"file"}
  sinkName={"aws_kinesis_firehose"} />

</li>
<li>

### Start Vector

```bash
vector --config vector.toml
```

That's it! Simple and to the point. Hit `ctrl+c` to exit.

</li>
</ol>

</div>



